# Week 5: SparkSQL SCD Type II Implementation Requirements
# Author: Abhyudaya B Tharakan 22f3001492
# Course: Introduction to Big Data
# Date: July 2025

# Core PySpark and Spark SQL dependencies
pyspark>=3.2.0,<4.0.0

# Data processing libraries
pandas>=1.3.0

# Date and time utilities (if needed for local testing)
python-dateutil>=2.8.0

# Logging and utilities
logging

# For cloud deployment (Google Cloud)
google-cloud-storage>=2.0.0
google-cloud-dataproc>=3.0.0

# Development and testing
pytest>=6.0.0
pytest-spark>=0.6.0

# Optional: For better development experience
jupyter>=1.0.0
matplotlib>=3.5.0
seaborn>=0.11.0

# Note: When running on Dataproc, most dependencies are pre-installed
# This file is primarily for local development and testing
